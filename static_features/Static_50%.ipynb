{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fjirigesi/Documents/OOSLAClassifier/service/Classifier/Model/XGBRegressionModel.py:2: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  from pandas import np\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.8.5\n",
      "tensorflow version: 2.5.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import sys\n",
    "from service.Classifier.DataLoader.DataLoader import DataLoader\n",
    "from service.Classifier.Enums.priority import Priority\n",
    "from service.Classifier.DataLoader.P2DataLoader import P2DataLoader\n",
    "from service.Classifier.DataLoader.P3DataLoader import P3DataLoader\n",
    "from service.Classifier.DataLoader.P4DataLoader import P4DataLoader\n",
    "from service.Classifier.Model.XGBRegressionModel import XGBRegressionModel\n",
    "from service.Classifier.PreProcessing.RegressionModelPreProcessor import RegressionModelPreProcessor\n",
    "import pickle\n",
    "import platform\n",
    "# from hpsklearn import HyperoptEstimator, xgboost_regression\n",
    "# from hyperopt import tpe\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "import csv\n",
    "from os import path\n",
    "import pathlib\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "import csv\n",
    "import os.path\n",
    "from os import path\n",
    "import pathlib\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from service.Classifier.Enums.LabelEnum import LabelEnum\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, confusion_matrix, classification_report\n",
    "from service.Classifier.PreProcessing.Utils.dataValidator import DataValidator\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from service.Classifier.Enums.LabelEnum import LabelEnum\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, confusion_matrix, classification_report\n",
    "from service.Classifier.PreProcessing.Utils.dataValidator import DataValidator\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "print('Python version:', platform.python_version())\n",
    "print('tensorflow version:', tf.__version__)\n",
    "sys.path.insert(0, os.path.abspath('../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeByPriority(priority):\n",
    "    # load new updated data via Features class\n",
    "    if priority == Priority.P2.value:\n",
    "        return P2DataLoader()\n",
    "    elif priority == Priority.P3.value:\n",
    "        return P3DataLoader()\n",
    "    elif priority == Priority.P4.value:\n",
    "        return P4DataLoader()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from service.Classifier.DataSplit.TrainTestSplit import TrainTestSplit\n",
    "from service.Classifier.Enums.dataTypeEnum import DataType\n",
    "\n",
    "def preprocessData(priority_value):\n",
    "\n",
    "    dataLoader = initializeByPriority(priority)\n",
    "    data_df = dataLoader.loadTrainingRawData()\n",
    "\n",
    "    # split data into train test 4:1\n",
    "    dataSplit = TrainTestSplit()\n",
    "    train_df, test_df = dataSplit.split(data_df)\n",
    "\n",
    "    # generate features\n",
    "    train_df, feature_names = dataLoader.transformRawDataToFeatures(train_df, DataType.TRAINDATA.value)\n",
    "    test_df, feature_names = dataLoader.transformRawDataToFeatures(test_df, DataType.VALIDATION.value)\n",
    "    print(train_df.shape)\n",
    "    print(test_df.shape)\n",
    "\n",
    "    # pre-processing the data based on model type\n",
    "    preprocessor = RegressionModelPreProcessor(feature_names)\n",
    "    train_X, train_y, test_X, test_y = preprocessor.preprocessing(train_df, test_df)\n",
    "    print(train_X.shape)\n",
    "    print(test_X.shape)\n",
    "    \n",
    "    return data_df, train_df, test_df, train_X, train_y, test_X, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "def getGCX():\n",
    "    url = \"http://paysplan.paysplan-ns.svc.33.tess.io/people/gcx/allNames\"\n",
    "    return requests.get(url).json()\n",
    "\n",
    "def checkGCX(row):\n",
    "    if row['Submitter'] in GCX['people']:\n",
    "        return 'Internal'\n",
    "    else:\n",
    "        return 'External'\n",
    "\n",
    "def extractLatestCategory(row):\n",
    "    try:\n",
    "        row['Category'][-1]['value']\n",
    "        return row['Category'][-1]['value']\n",
    "    except:\n",
    "        return 'NAN'\n",
    "\n",
    "def getStaticMetrics(data_df):\n",
    "    staticMetrics = data_df[[\"_id\", \"assignee\", \"reporter\",\"issueType\", \"summary\"]].copy()\n",
    "    staticMetrics = staticMetrics.rename({'_id': \"issueKey\",'assignee': 'Owner', \"issueType\": 'Type', \n",
    "                                          'reporter': 'Submitter'}, axis='columns')\n",
    "    \n",
    "    staticMetrics['ESC'] = staticMetrics.apply(checkGCX, axis=1)\n",
    "    \n",
    "    with open('/data/ExtarctedInfo.pickle', 'rb') as f:\n",
    "        allInfor = pickle.load(f)\n",
    "        \n",
    "    # Join the table \n",
    "    right = allInfor[[\"issueKey\",\"categoryBugs\", \"severity\" ]]\n",
    "    StaticMetricsResult = pd.merge(staticMetrics, right, how=\"left\", on=\"issueKey\")\n",
    "    \n",
    "    StaticMetricsResult = StaticMetricsResult.rename({'categoryBugs': 'Category', 'severity': 'Severity', 'summary': 'Summary'}, axis='columns')\n",
    "    return StaticMetricsResult\n",
    "\n",
    "def embeddingValues(col_name, staticMetrics):\n",
    "    List = staticMetrics[col_name].tolist()\n",
    "    uniqueListA = list(set(List))\n",
    "    \n",
    "    def getIndex(row):\n",
    "        return uniqueListA.index(row[col_name])\n",
    "\n",
    "    new_col_name = col_name + '_Emb'\n",
    "    staticMetrics[new_col_name] = staticMetrics.apply(getIndex, axis=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on text columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary = Pipeline([\n",
    "                ('selector', TextSelector(key='Summary')),\n",
    "                ('tfidf', TfidfVectorizer(stop_words='english'))\n",
    "            ])\n",
    "\n",
    "Owner_Emb =  Pipeline([\n",
    "                ('selector', NumberSelector(key='Owner_Emb')),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "Submitter_Emb =  Pipeline([\n",
    "                ('selector', NumberSelector(key='Submitter_Emb')),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "ESC_Emb =  Pipeline([\n",
    "                ('selector', NumberSelector(key='ESC_Emb')),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "Type_Emb =  Pipeline([\n",
    "                ('selector', NumberSelector(key='Type_Emb')),\n",
    "                ('standard', StandardScaler()),\n",
    "            ])\n",
    "\n",
    "Severity_Emb =  Pipeline([\n",
    "                ('selector', NumberSelector(key='Severity_Emb')),\n",
    "                ('standard', StandardScaler()),\n",
    "            ])\n",
    "Category_Emb =  Pipeline([\n",
    "                ('selector', NumberSelector(key='Category_Emb')),\n",
    "                ('standard', StandardScaler()),\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(submission, priority):\n",
    "    coefficients_Dict = {\"P2\": 1, \"P3\": 1, \"P4\": 1, \"ALL\": 1}\n",
    "    coefficients = coefficients_Dict[priority]\n",
    "    priorityDays_dict = {\"P2\": 20, \"P3\": 60, \"P4\": 90}\n",
    "    daysAllowedList = priorityDays_dict[priority]\n",
    "    \n",
    "    submission[\"prediction\"] = pd.Series(submission[\"ClosedDay\"] >= coefficients * daysAllowedList,\n",
    "                                         index=submission.index)\n",
    "    \n",
    "    submission[\"truth\"] = pd.Series(submission[\"Actual\"] >= daysAllowedList, index=submission.index)\n",
    "    # submission[\"issueType\"] = test_df[\"issueType\"]\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from service.Classifier.Enums.LabelEnum import LabelEnum\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, confusion_matrix, classification_report\n",
    "from service.Classifier.PreProcessing.Utils.dataValidator import DataValidator\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "feats = FeatureUnion([('Owner_Emb', Owner_Emb), \n",
    "                      ('Submitter_Emb', Submitter_Emb),\n",
    "                      ('ESC_Emb', ESC_Emb),\n",
    "                      ('Type_Emb', Type_Emb),\n",
    "                      ('Severity_Emb', Severity_Emb),\n",
    "                      ('Category_Emb', Category_Emb),\n",
    "                      ('Summary', Summary)])\n",
    "\n",
    "feature_processing = Pipeline([('feats', feats)])\n",
    "\n",
    "\n",
    "def evaluate_static_result(staticMetrics_trainX, staticMetrics_trainy, staticMetrics_testX, staticMetrics_testy):\n",
    "\n",
    "    feature_processing.fit_transform(staticMetrics_trainX)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('features',feats),\n",
    "        ('regressor', XGBRegressor(max_depth=5, n_estimators=100, learning_rate=0.05)),\n",
    "    ])\n",
    "\n",
    "\n",
    "    pipeline.fit(staticMetrics_trainX, staticMetrics_trainy)\n",
    "\n",
    "    predictions = np.rint(pipeline.predict(staticMetrics_testX)).astype(np.int64)\n",
    "\n",
    "\n",
    "    submission = pd.DataFrame({'ClosedDay': predictions, 'Actual': staticMetrics_testy['ResolvedDay'].tolist()})\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(predictions, staticMetrics_testy))\n",
    "\n",
    "    mae = mean_absolute_error(predictions, staticMetrics_testy)\n",
    "\n",
    "    valid(submission, priority)\n",
    "\n",
    "    f1 = f1_score(submission[\"truth\"], submission[\"prediction\"])\n",
    "    precision = precision_score(submission[\"truth\"], submission[\"prediction\"])\n",
    "    recall = recall_score(submission[\"truth\"], submission[\"prediction\"])\n",
    "\n",
    "\n",
    "    print('rmse:', rmse)\n",
    "    print('mae:', mae)\n",
    "    print(confusion_matrix(submission[\"truth\"], submission[\"prediction\"]))\n",
    "    print(classification_report(submission[\"truth\"], submission[\"prediction\"]))\n",
    "    \n",
    "    return (staticMetrics_testy, predictions, submission[\"truth\"], submission[\"prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_static_feature(priority):\n",
    "    \n",
    "    data_df, train_df,test_df, train_X, train_y, test_X, test_y = preprocessData(priority)\n",
    "\n",
    "    \n",
    "\n",
    "    staticMetrics = getStaticMetrics(data_df)\n",
    "    \n",
    "    staticMetrics['Category'] = staticMetrics.apply(extractLatestCategory, axis=1)\n",
    "\n",
    "    # \"\"\"\n",
    "    # Embedding all columns except \"Summary\"\n",
    "    # \"\"\"\n",
    "\n",
    "    colNames = [\"Owner\", \"Submitter\", \"Type\", \"ESC\", \"Category\", \"Severity\"]\n",
    "    \n",
    "    for colName in colNames:\n",
    "        embeddingValues(colName, staticMetrics)\n",
    "\n",
    "    staticMetrics = staticMetrics.rename({\"issueKey\": \"keyID\"}, axis='columns')\n",
    "    staticMetrics = staticMetrics.drop_duplicates(subset='keyID', keep=\"last\")\n",
    "    staticMetrics[\"keyID\"].is_unique\n",
    "\n",
    "    AllMetrics_train = pd.merge(train_df, staticMetrics, how=\"left\", on=\"keyID\")\n",
    "    AllMetrics_test = pd.merge(test_df, staticMetrics, how=\"left\", on=\"keyID\")\n",
    "\n",
    "\n",
    "    # get training data \n",
    "    staticMetrics_trainX = AllMetrics_train[[\"Owner_Emb\", \"Submitter_Emb\", \"ESC_Emb\", \"Type_Emb\", \"Severity_Emb\", \"Category_Emb\", \"Summary\"]]\n",
    "    staticMetrics_trainy = AllMetrics_train[[\"ResolvedDay\"]]\n",
    "    # get testing data \n",
    "    staticMetrics_testX = AllMetrics_test[[\"Owner_Emb\", \"Submitter_Emb\", \"ESC_Emb\", \"Type_Emb\", \"Severity_Emb\", \"Category_Emb\", \"Summary\"]]\n",
    "    staticMetrics_testy = AllMetrics_test[[\"ResolvedDay\"]]\n",
    "\n",
    "    return (staticMetrics_trainX, staticMetrics_trainy, staticMetrics_testX, staticMetrics_testy)\n",
    "\n",
    "# static_X=np.concatenate((staticMetrics_trainX, staticMetrics_testX))\n",
    "# static_y = np.concatenate((staticMetrics_trainy, staticMetrics_testy))\n",
    "# print(static_X.shape)\n",
    "# print(static_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get P1 Static Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fjirigesi/anaconda3/lib/python3.8/site-packages/pymongo/common.py:781: UserWarning: The value of ssl must be 'true' or 'false'\n",
      "  warnings.warn(str(exc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The project is not in embedding: NATBEMCR\n",
      "The project is not in embedding: PX\n",
      "The project is not in embedding: CSCNPLAT\n",
      "The project is not in embedding: GGRIP\n",
      "The project is not in embedding: PROBLEM\n",
      "(2655, 12)\n",
      "(639, 12)\n",
      "(2655, 8)\n",
      "(639, 8)\n"
     ]
    }
   ],
   "source": [
    "priority = Priority.P2.value\n",
    "GCX = getGCX()\n",
    "staticMetrics_trainX, staticMetrics_trainy, staticMetrics_testX, staticMetrics_testy = extract_static_feature(priority)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracted featrues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Owner_Emb</th>\n",
       "      <th>Submitter_Emb</th>\n",
       "      <th>ESC_Emb</th>\n",
       "      <th>Type_Emb</th>\n",
       "      <th>Severity_Emb</th>\n",
       "      <th>Category_Emb</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1332</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>[Adyen Issue] DE - MP Unable to verify account...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>190</td>\n",
       "      <td>989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Seller cannot cancel item from ResolutionCenter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1298</td>\n",
       "      <td>490</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>MP: Seller unable to update the details throug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>341</td>\n",
       "      <td>1277</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>ANDR - See cancellation details from email doe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1053</td>\n",
       "      <td>324</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>Top of funnel for B2C registration (PPA) has d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>130</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>US UK - Email sent to members in German langua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2026</td>\n",
       "      <td>1002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>MP: Member's payouts on hold due to USER_PAYOU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>516</td>\n",
       "      <td>658</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>GCX unable to check Job Statuses - CSReadJobs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>1002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>[Adyen Issue] MP: Possible Data Transmission I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>232</td>\n",
       "      <td>1342</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>MP - US - Member was charged for 2 labels but ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Owner_Emb  Submitter_Emb  ESC_Emb  Type_Emb  Severity_Emb  Category_Emb  \\\n",
       "0          4           1332        1         0             2            18   \n",
       "1        190            989        0         0             1             6   \n",
       "2       1298            490        1         0             2            18   \n",
       "3        341           1277        0         0             0             3   \n",
       "4       1053            324        0         0             1             8   \n",
       "5        130            242        0         0             0             3   \n",
       "6       2026           1002        1         0             1             6   \n",
       "7        516            658        0         0             0             3   \n",
       "8          4           1002        1         0             1            14   \n",
       "9        232           1342        1         0             0             3   \n",
       "\n",
       "                                             Summary  \n",
       "0  [Adyen Issue] DE - MP Unable to verify account...  \n",
       "1    Seller cannot cancel item from ResolutionCenter  \n",
       "2  MP: Seller unable to update the details throug...  \n",
       "3  ANDR - See cancellation details from email doe...  \n",
       "4  Top of funnel for B2C registration (PPA) has d...  \n",
       "5  US UK - Email sent to members in German langua...  \n",
       "6  MP: Member's payouts on hold due to USER_PAYOU...  \n",
       "7  GCX unable to check Job Statuses - CSReadJobs ...  \n",
       "8  [Adyen Issue] MP: Possible Data Transmission I...  \n",
       "9  MP - US - Member was charged for 2 labels but ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "staticMetrics_trainX.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 9.870602564796906\n",
      "mae: 8.020344287949921\n",
      "[[127 231]\n",
      " [ 50 231]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.72      0.35      0.47       358\n",
      "        True       0.50      0.82      0.62       281\n",
      "\n",
      "    accuracy                           0.56       639\n",
      "   macro avg       0.61      0.59      0.55       639\n",
      "weighted avg       0.62      0.56      0.54       639\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p2_regression_true, p2_regression_pred, p2_classification_true, p2_classification_pred = evaluate_static_result(staticMetrics_trainX, staticMetrics_trainy, staticMetrics_testX, staticMetrics_testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get P2 Static Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fjirigesi/anaconda3/lib/python3.8/site-packages/pymongo/common.py:781: UserWarning: The value of ssl must be 'true' or 'false'\n",
      "  warnings.warn(str(exc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2697, 16)\n",
      "(711, 16)\n",
      "(2697, 12)\n",
      "(711, 12)\n",
      "rmse: 19.090133385766514\n",
      "mae: 14.109704641350211\n",
      "[[449  62]\n",
      " [150  50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.75      0.88      0.81       511\n",
      "        True       0.45      0.25      0.32       200\n",
      "\n",
      "    accuracy                           0.70       711\n",
      "   macro avg       0.60      0.56      0.56       711\n",
      "weighted avg       0.66      0.70      0.67       711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "priority = Priority.P3.value\n",
    "\n",
    "staticMetrics_trainX, staticMetrics_trainy, staticMetrics_testX, staticMetrics_testy = extract_static_feature(priority)\n",
    "\n",
    "p3_regression_true, p3_regression_pred, p3_classification_true, p3_classification_pred = evaluate_static_result(staticMetrics_trainX, staticMetrics_trainy, staticMetrics_testX, staticMetrics_testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get P3 Static Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fjirigesi/anaconda3/lib/python3.8/site-packages/pymongo/common.py:781: UserWarning: The value of ssl must be 'true' or 'false'\n",
      "  warnings.warn(str(exc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1543, 16)\n",
      "(402, 16)\n",
      "(1543, 12)\n",
      "(402, 12)\n",
      "rmse: 22.954909294016332\n",
      "mae: 16.76865671641791\n",
      "[[274  14]\n",
      " [ 99  15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.73      0.95      0.83       288\n",
      "        True       0.52      0.13      0.21       114\n",
      "\n",
      "    accuracy                           0.72       402\n",
      "   macro avg       0.63      0.54      0.52       402\n",
      "weighted avg       0.67      0.72      0.65       402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "priority = Priority.P4.value\n",
    "\n",
    "staticMetrics_trainX, staticMetrics_trainy, staticMetrics_testX, staticMetrics_testy = extract_static_feature(priority)\n",
    "\n",
    "p4_regression_true, p4_regression_pred, p4_classification_true, p4_classification_pred = evaluate_static_result(staticMetrics_trainX, staticMetrics_trainy, staticMetrics_testX, staticMetrics_testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cancatenate all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression results\n",
    "regression_true = pd.concat([p2_regression_true, p3_regression_true])\n",
    "regression_true = pd.concat([regression_true, p4_regression_true])\n",
    "\n",
    "regression_pred = np.concatenate((p2_regression_pred, p3_regression_pred), axis=0)\n",
    "regression_pred = np.concatenate((regression_pred, p4_regression_pred), axis=0)\n",
    "\n",
    "## classification results\n",
    "classification_true = pd.concat([p2_classification_true, p3_classification_true])\n",
    "classification_true = pd.concat([classification_true, p4_classification_true])\n",
    "\n",
    "classification_pred = pd.concat([p2_classification_pred, p3_classification_pred])\n",
    "classification_pred = pd.concat([classification_pred, p4_classification_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Static Features results on all data---\n",
      "RMSE: 17.860415\n",
      "MAE: 12.753247\n",
      "[[864 249]\n",
      " [302 202]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.74      0.78      0.76      1113\n",
      "        True       0.45      0.40      0.42       504\n",
      "\n",
      "    accuracy                           0.66      1617\n",
      "   macro avg       0.59      0.59      0.59      1617\n",
      "weighted avg       0.65      0.66      0.65      1617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"---Static Features results on all data---\")\n",
    "rmse = np.sqrt(mean_squared_error(regression_pred, regression_true))\n",
    "print(\"RMSE: %f\" % rmse)\n",
    "mae = mean_absolute_error(regression_pred, regression_true)\n",
    "print(\"MAE: %f\" % mae)\n",
    "print(confusion_matrix(classification_true, classification_pred))\n",
    "print(classification_report(classification_true, classification_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
